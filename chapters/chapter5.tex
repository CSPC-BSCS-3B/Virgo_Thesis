\chapter{Summary of Findings, Conclusions, and Recommendations}
\begin{refsection}

This chapter presents the summary of findings, conclusions, and recommendations derived from the results of the study.

\section{Summary}

Finding relevant thesis literature in a university library like in CSPC can be difficult for many students and researchers. Most people have a hard time finding the exact thesis they need because the current library website only allows searches by the exact title. If a user does not know the precise title, it becomes a struggle to locate the right documents. Making things even harder, library rules do not allow theses to be taken out of the building, which means users must visit the library in person to access important academic materials. Because of these challenges, this study explored creating a chatbot that would let users search for thesis papers using topics, keywords, or even general descriptions, all while making the system accessible everywhere.

To solve these problems, the researchers built a new chatbot system that uses Retrieval-Augmented Generation (RAG) along with a state of the art Large Language Model (LLM). The process involved preprocessing and converting 290+ undergraduate thesis papers into digital embeddings and be store on FAISS vector database, which allows the chatbot to understand and search for relevant information based on a user's question in natural language. The chatbot retrieves and shows the most fitting parts of the theses and uses the Gemini 2.5-flash model to generate accurate and appropriate responses. All the system steps from preparing the thesis files to designing a simple user interface work together to make searching faster and more effective. The system was tested using different automated metrics from RAGAS evaluation framework including context precision, context recall, answer Relevance and faithfulness. Additionally, a user questionnaire with a 5-point likert scale to assess a human-centered performance.

Results were promising, with the RAG-based chatbot achieving high Context Precision (0.9167) and Faithfulness (0.9179), demonstrating strong capability to return relevant content while maintaining source grounding. Context Recall reached 0.8711, showing successful thesis retrieval despite minor gaps. Answer Relevancy scored 0.8625, indicating generated responses effectively address user queries. The high faithfulness score suggests outputs are grounded in retrieved documents, reducing hallucinations. However, evaluation reveals important dependencies: thesis PDF quality, OCR errors, and prompt variability remain optimization targets. Despite these limitations, overall performance demonstrates the system's effectiveness in modernizing thesis discovery.

The deployment of the chatbot was observed to make thesis search more intuitive, significantly lowering entry barriers for users and reducing time spent locating needed materials. Moreover, it became evident to the researchers that several factors influenced system performance, such as thesis data quality,  and user prompts that significantly impairs the chatbot's accuracy.

\section{Findings}

The following are the key findings from the study:

\begin{enumerate}
    \item By integrating a document ingestion and retrieval module, all thesis documents in PDF format are standardized and divided using thesis-aware boundaries, enriched with metadata, embedded, and indexed in FAISS. This makes them discoverable through semantic search rather than exact keyword matching, resulting in much better retrieval of abstracts, authors, chapters, and themes compared to traditional databases. The pipeline’s token-based chunking and content-type tagging (such as abstract, methodology, or results) really improve context alignment and ranking, so queries like “give me the complete abstract” or “find theses related to nursing” return relevant sections directly, whereas traditional catalogs usually require exact titles or strict keyword fields.

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS as the vector database, using all-MiniLM-L6-v2 from HuggingFace for vector embeddings and Google Gemini 2.5-flash as the generative LLM, user queries are matched to semantically relevant thesis chunks, which consistently yields more precise answers to intent-driven questions (such as complete abstracts, author-focused lookups, or chapter-specific content) than the current yet traditional keyword-based search that depends on exact titles and rigid field matches. The RAG pipeline grounds answers in retrieved chunks, so the chatbot can compose context-aware responses tied to real thesis passages, while the thesis-aware chunking and metadata (abstract, methodology, results, and chapter tags) improve ranking and reduce irrelevant matches.

    \item Using the RAGAS as the RAG evaluation framework the system sustained high results in Context Precision (0.9167), Context Recall (0.8711), Answer Relevancy (0.8625), and Faithfulness (0.9179). Together these values indicate a robust retrieval-and-generation pipeline: high precision and recall show the FAISS-backed retrieval reliably returns the necessary thesis passages, while the strong answer relevancy demonstrates the LLM composes useful responses from those sources. The notably high faithfulness score suggests that generated outputs are, in most cases, directly grounded in retrieved documents, which materially reduces the likelihood of unsupported or hallucinated assertions. The evaluation still highlights the usual dependencies and limitations, chiefly the quality and structure of ingested thesis PDFs, OCR/formatting errors, and user prompt variability which remain important targets for continued optimization even as overall performance is strong.
\end{enumerate}

\section{Conclusions}

    Based on the findings, the researchers come up with the folling conclusions:

\begin{enumerate}
    \item It is evident that the integration of a thesis-aware document ingestion pipeline is a critical first step in modernizing thesis discovery. By standardizing documents, applying content-aware chunking, and enriching the data with metadata before indexing, the system overcomes the limitations of traditional keyword-based catalogs. This approach makes thesis content more accessible and discoverable through semantic search, allowing users to find relevant information based on intent rather than exact phrasing.

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS for approximate nearest-neighbor search, using all-MiniLM-L6-v2 for vector embeddings and Google Gemini 2.5-flash as the generative LLM, user queries are matched to semantically relevant thesis chunks, which consistently yields more precise answers to intent-driven questions than the current yet traditional keyword-based search that depends on exact titles and rigid field matches. By combining semantic search with the generative capabilities of Google Gemini 2.5-flash, the RAG chatbot offers a robust solution for efficient and accurate thesis retrieval in the CSPC Library.

    \item The evaluation demonstrates that the RAG-based chatbot effectively retrieves relevant information and generates contextually appropriate responses. However, it also highlights the importance of document quality and user input in optimizing performance. Continuous improvements in these areas are essential to enhance the system's reliability and ensure that it consistently meets user needs in thesis discovery.
\end{enumerate}

\section{Recommendations}

\begin{enumerate}
    \item Future work should focus on improving the faithfulness and recall of generated responses. This may involve refining the chunking and retrieval process, integrating more advanced embedding models, or incorporating additional post-processing checks to ensure factual consistency.
    \item Increasing the diversity and volume of ingested thesis documents, and exploring the inclusion of other academic materials (e.g., journal articles, conference papers), can further improve retrieval coverage and system robustness.
    \item To complement automated metrics, future evaluations should include human-in-the-loop assessments, such as expert reviews or user feedback surveys, to better capture subjective aspects of response quality and user satisfaction.
    \item Continued development of the chatbot interface, including user-friendly features like advanced filtering, citation export, and personalized recommendations, will enhance usability and adoption within the academic community.
    \item For broader impact, consider deploying the system on scalable infrastructure and integrating it with other institutional platforms, ensuring accessibility for all CSPC stakeholders.
\end{enumerate}

%=======================================================%
%%%%% Do not delete this part %%%%%%
\clearpage

\printbibliography[heading=subbibintoc, title={\centering Notes}]
\end{refsection}