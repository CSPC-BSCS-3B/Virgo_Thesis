\chapter{Summary of Findings, Conclusions, and Recommendations}
\begin{refsection}

This chapter presents the summary of findings, conclusions, and recommendations derived from the results of the study.

\section{Summary}

Finding relevant thesis literature in a university library like in CSPC can be difficult for many students and researchers. Most people have a hard time finding the exact thesis they need because the current library website only allows searches by the exact title. If a user does not know the precise title, it becomes a struggle to locate the right documents. Making things even harder, library rules do not allow theses to be taken out of the building, which means users must visit the library in person to access important academic materials. Because of these challenges, this study explored creating a chatbot that would let users search for thesis papers using topics, keywords, or even general descriptions, all while making the system accessible everywhere.

To solve these problems, the researchers built a new chatbot system that uses Retrieval-Augmented Generation (RAG) along with a state-of-the-art Large Language Model (LLM). The process involved preprocessing and converting 290+ undergraduate thesis papers into digital embeddings and storing them in a FAISS vector database, which allows the chatbot to understand and search for relevant information based on a user's questions in natural language. The chatbot retrieves and displays the most fitting parts of the theses and uses the Gemini 2.5-flash model to generate accurate and appropriate responses. All the system steps, from preparing the thesis files to designing a simple user interface, work together to make searching faster and more effective. Moreover, the chatbot was deployed in the cloud for easy user accessibility. Then, the system was tested using different automated metrics from the RAGAS evaluation framework, including context precision, context recall, answer relevance, and faithfulness. Additionally, a user questionnaire with a 5-point Likert scale was used to assess human-centered performance.

Results from the RAG-based chatbot evaluation are promising in both automated and human evaluations. Context Precision (0.9167) and Faithfulness (0.9179) demonstrate strong capability to return relevant content while maintaining source grounding and reducing the likelihood of hallucinations. Context Recall reached 0.8711, showing successful thesis retrieval despite minor gaps. Answer Relevancy scored 0.8625, indicating that generated responses effectively address user queries. In the human evaluation, users strongly agreed (4.5) with the chatbot's overall response quality and performance, which indicates that the chatbot works well for its main task of helping users find information and answer questions. Moreover, regarding the RAG chatbot's overall effectiveness and usability, users strongly agreed (4.3) that the chatbot provides useful and relevant answers, and they also demonstrated intent to use the chatbot again in the future to support their academic needs. However, both evaluations reveal important dependencies: thesis PDF quality, OCR errors, and prompt variability remain optimization targets. Despite these limitations, overall performance demonstrates the system's effectiveness in modernizing thesis discovery.

\section{Findings}

The following are the key findings from the study:

\begin{enumerate}
    \item By integrating a document ingestion and retrieval module, all thesis documents in PDF format are standardized and divided using thesis-aware boundaries, enriched with metadata, embedded, and indexed in FAISS. This makes them discoverable through semantic search rather than exact keyword matching, resulting in much better retrieval of abstracts, authors, chapters, and themes compared to traditional databases. The pipeline’s token-based chunking and content-type tagging (such as abstract, methodology, or results) significantly improve context alignment and ranking, so queries like “give me the complete abstract” or “find theses related to nursing” return relevant sections directly, whereas traditional catalogs usually require exact titles or strict keyword fields.

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS as the vector database, using all-MiniLM-L6-v2 from HuggingFace for vector embeddings and Google Gemini 2.5-flash as the generative LLM, user queries are matched to semantically relevant thesis chunks, which consistently yield more precise answers to intent-driven questions (such as complete abstracts, author-focused lookups, or chapter-specific content) than the current traditional keyword-based search that depends on exact titles and rigid field matches. The RAG pipeline grounds answers in retrieved chunks, allowing the chatbot to compose context-aware responses tied to real thesis passages, while the thesis-aware chunking and metadata (abstract, methodology, results, and chapter tags) improve ranking and reduce irrelevant matches.

    \item Using RAGAS as the automated evaluation and survey questionnaires for human evaluation, Context Precision (0.9167), Context Recall (0.8711), Answer Relevancy (0.8625), and Faithfulness (0.9179) indicate a strong retrieval-and-generation pipeline: high precision and recall show that the FAISS-backed retrieval returns the necessary thesis passages, while the strong answer relevancy demonstrates that the LLM composes useful responses from retrieved sources. The high faithfulness score suggests that generated outputs are, in most cases, directly grounded in retrieved documents, which materially reduces the likelihood of hallucinations. In the human evaluation, the chatbot achieved a Strongly Agree (4.5) rating for the overall response quality and performance, as well as a Strongly Agree (4.3) rating for the overall effectiveness and usability of the chatbot. However, both evaluations still highlight the usual dependencies and limitations, chiefly the quality and structure of ingested thesis PDFs, OCR/formatting errors, and user prompt variability, which remain important targets for continued optimization even as overall performance is strong.

\end{enumerate}

\section{Conclusions}

    Based on the findings, the researchers come up with the following conclusions:

\begin{enumerate}
    \item It is evident that the integration of a thesis-aware document ingestion pipeline is a critical first step in modernizing thesis discovery. By standardizing documents, applying content-aware chunking, and enriching the data with metadata before indexing, the system overcomes the limitations of traditional keyword-based catalogs. This approach makes thesis content more accessible and discoverable through semantic search, allowing users to find relevant information based on intent rather than exact phrasing.

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS for approximate nearest-neighbor search, using sentence-transformers/all-MiniLM-L6-v2 (HuggingFace) for vector embeddings and Google Gemini 2.5-flash as the generative LLM, user queries are matched to semantically relevant thesis chunks, which consistently yields more precise answers to intent-driven questions than the current yet traditional keyword-based search that depends on exact titles and rigid field matches. By combining semantic search with the generative capabilities of Google Gemini 2.5-flash, the RAG chatbot offers a robust solution for efficient and accurate thesis retrieval in the CSPC Library.

    \item The evaluation demonstrates that the RAG-based chatbot effectively retrieves relevant information and generates contextually appropriate responses. However, it also highlights the importance of document quality and user input in optimizing performance. Continuous improvements in these areas are essential to enhance the system's reliability and ensure that it consistently meets user needs in thesis discovery.
\end{enumerate}

\section{Recommendations}
Based on the conclusions, the researchers recommend the following:
\begin{enumerate}
    \item Future work should focus on enhancing the retrieval-and-generation pipeline by addressing document quality, refining chunking strategies, and optimizing user prompts to further improve context precision, recall, and overall system performance.
    \item Increasing the diversity and volume of ingested thesis documents, and exploring the inclusion of other academic materials (e.g., journal articles, conference papers), can further improve retrieval coverage and system robustness.
    \item To complement automated metrics, future evaluations should include human-in-the-loop assessments, such as expert review to better capture subjective aspects of response quality and user satisfaction.
    \item Continued development of the chatbot interface, including user-friendly features like advanced filtering, citation export, and personalized recommendations, will enhance usability and adoption within the academic community.
    \item For broader impact, consider deploying the system on scalable infrastructure and integrating it with other institutional platforms, ensuring accessibility for all CSPC stakeholders.
\end{enumerate}

%=======================================================%
%%%%% Do not delete this part %%%%%%
\clearpage

\printbibliography[heading=subbibintoc, title={\centering Notes}]
\end{refsection}