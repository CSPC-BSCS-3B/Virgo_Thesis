\chapter{Summary of Findings, Conclusions, and Recommendations}
\begin{refsection}

This chapter presents the summary of findings, conclusions, and recommendations derived from the results of the study.

\section*{Summary}

Finding relevant thesis literature in a university library like CSPC can be difficult for many students and researchers. Most people have a hard time finding the exact thesis they need because the current library website only allows searches by the exact title. If a user does not know the precise title, it becomes a struggle to locate the right documents. Making things even harder, library rules do not allow theses to be taken out of the building, which means users must visit the library in person to access important academic materials. Because of these challenges, this study explored creating a chatbot that would let users search for thesis papers using topics, keywords, or even general descriptions, all while making the system available from anywhere.

To solve these problems, the researchers built a new chatbot system that uses Retrieval-Augmented Generation (RAG) along with a Large Language Model (LLM). The process involved converting 290 undergraduate thesis papers into digital "embeddings" for a vector database, which allows the chatbot to understand and search for relevant information based on a user's question in natural language. The chatbot retrieves and shows the most fitting parts of the theses and uses the Gemini 2.5-flash model to generate accurate and appropriate responses. All the system steps from preparing the thesis files to designing a simple user interface—work together to make searching faster and more effective. The system was tested using different metrics, like how precise and complete the answers were, how well they matched the user's needs, and how much the chatbot's answers were based on real sources.

The results were promising, with the RAG-based chatbot achieving high performance in both precision and answer relevancy. Specifically, the system scored 0.818 for Context Precision, demonstrating strong capability to return highly relevant content, and 0.737 for Answer Relevancy, indicating that responses were generally useful and addressed user queries appropriately. Context Recall reached 0.721, showing that most relevant supporting information was captured, though some supporting details were still missed. The metric for Faithfulness at 0.585 highlighted that while most answers were grounded in the source documents, there is room for improvement in ensuring all generated content is directly traceable to original texts. The deployment of the chatbot was observed to make thesis search more intuitive, significantly lowering entry barriers for users and reducing time spent locating needed materials. Moreover, it became evident to the researchers that several factors influenced system performance, such as thesis data quality and user prompts that significantly impairs the chatbot's accuracy.

\section*{Findings}

The following are the key findings from the study:

\begin{enumerate}
    \item By integrating a document ingestion and retrieval module, all thesis documents in PDF format are standardized and divided using thesis-aware boundaries, enriched with metadata, embedded, and indexed in FAISS. This makes them discoverable through semantic search rather than exact keyword matching, resulting in much better retrieval of abstracts, authors, chapters, and themes compared to traditional storage. The pipeline’s token-based chunking and content-type tagging (such as abstract, methodology, or results) improve context alignment and ranking, so queries like “give me the complete abstract” or “find theses on artificial intelligence” return relevant sections directly, whereas traditional catalogs usually require exact titles or strict keyword fields

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS for approximate nearest-neighbor search, and Google Gemini embeddings, user queries are matched to semantically relevant thesis chunks across languages and formats, which consistently yields more precise answers to intent-driven questions (such as complete abstracts, author-focused lookups, or chapter-specific content) than traditional catalog or keyword search that depends on exact titles and rigid field matches. The RAG pipeline grounds answers in retrieved chunks, so the chatbot can compose context-aware responses tied to real thesis passages, while the thesis-aware chunking and metadata (abstract, methodology, results, chapter tags, and priority flags) improve ranking and reduce irrelevant matches, which traditional systems typically cannot achieve without extensive manual cataloging.

    \item The system achieved high scores in Context Precision (0.818) and Answer Relevancy (0.737), indicating that most retrieved and generated responses were both relevant and useful. Context Recall (0.721) showed that the system was able to capture most of the necessary information, though some relevant content was occasionally missed. Faithfulness (0.585) revealed that while the majority of responses were grounded in the source documents, there were instances where generated answers could be more closely aligned with the original texts. The evaluation also identified limitations, such as the dependency on the quality and structure of ingested thesis documents, and the need for further optimization to enhance faithfulness and recall. 
\end{enumerate}

\section*{Conclusions}

\begin{enumerate}
    \item \textbf{RAG as a Transformative Tool:} The study concludes that Retrieval-Augmented Generation is a transformative approach for academic literature retrieval, addressing the shortcomings of both traditional search and standalone LLMs. By combining semantic search with generative capabilities, the RAG chatbot offers a robust solution for efficient and accurate thesis retrieval in the CSPC Library.
    \item \textbf{Metric-Driven Evaluation:} The use of multi-dimensional metrics---answer relevancy, context precision, context recall, and faithfulness---provides a comprehensive framework for assessing and refining academic AI systems. These metrics not only highlight the system’s strengths but also guide ongoing improvements.
    \item \textbf{Practical Impact:} The successful deployment of the RAG chatbot demonstrates its practical value for students, faculty, and library management, streamlining the research process and enhancing access to academic resources.
\end{enumerate}

\section*{Recommendations}

\begin{enumerate}
    \item Future work should focus on improving the faithfulness and recall of generated responses. This may involve refining the chunking and retrieval process, integrating more advanced embedding models, or incorporating additional post-processing checks to ensure factual consistency.
    \item Increasing the diversity and volume of ingested thesis documents, and exploring the inclusion of other academic materials (e.g., journal articles, conference papers), can further improve retrieval coverage and system robustness.
    \item To complement automated metrics, future evaluations should include human-in-the-loop assessments, such as expert reviews or user feedback surveys, to better capture subjective aspects of response quality and user satisfaction.
    \item Continued development of the chatbot interface, including user-friendly features like advanced filtering, citation export, and personalized recommendations, will enhance usability and adoption within the academic community.
    \item For broader impact, consider deploying the system on scalable infrastructure and integrating it with other institutional platforms, ensuring accessibility for all CSPC stakeholders.
\end{enumerate}

%=======================================================%
%%%%% Do not delete this part %%%%%%
\clearpage

\printbibliography[heading=subbibintoc, title={\centering Notes}]
\end{refsection}