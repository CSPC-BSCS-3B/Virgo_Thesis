\chapter{Summary of Findings, Conclusions, and Recommendations}
\begin{refsection}

This chapter presented the summary of findings, conclusions, and recommendations derived from the results of the study.

\section{Summary}


Finding relevant thesis literature in a university library like CSPC was difficult for many students and researchers. Most people had a hard time finding the exact thesis they needed because the library website only allowed searches by the exact title. If a user did not know the precise title, it became a struggle to locate the right documents. Making things even harder, library rules did not allow theses to be taken out of the building, which meant users had to visit the library in person to access important academic materials. Because of these challenges, this study explored creating a chatbot that would allow users to search for thesis papers using topics, keywords, or even general descriptions, all while making the system accessible everywhere.


To solve these problems, the researchers built a new chatbot system that used Retrieval-Augmented Generation (RAG) along with a state-of-the-art Large Language Model (LLM). The process involved preprocessing and converting over 290 undergraduate thesis papers into digital embeddings and storing them on a FAISS vector database, which allowed the chatbot to understand and search for relevant information based on a user's question in natural language. The chatbot retrieved and showed the most fitting parts of the theses and used the Gemini 2.5-flash model to generate accurate and appropriate responses. All the system steps, from preparing the thesis files to designing a simple user interface, worked together to make searching faster and more effective. The system was tested using different automated metrics from the RAGAS evaluation framework, including context precision, context recall, answer relevance, and faithfulness. Additionally, a user questionnaire with a 5-point Likert scale was used to assess human-centered performance.


The results were promising, with the RAG-based chatbot achieving high Context Precision (0.9167) and Faithfulness (0.9179), demonstrating strong capability to return relevant content while maintaining source grounding. Context Recall reached 0.8711, showing successful thesis retrieval despite minor gaps. Answer Relevancy scored 0.8625, indicating that generated responses effectively addressed user queries. The high faithfulness score suggested outputs were grounded in retrieved documents, reducing hallucinations. However, the evaluation revealed important dependencies: thesis PDF quality, OCR errors, and prompt variability remained optimization targets. Despite these limitations, overall performance demonstrated the system's effectiveness in modernizing thesis discovery.


The deployment of the chatbot made thesis search more intuitive, significantly lowering entry barriers for users and reducing time spent locating needed materials. Moreover, it became evident to the researchers that several factors influenced system performance, such as thesis data quality and user prompts, which significantly impaired the chatbot's accuracy.

\section{Findings}

The following are the key findings from the study:

\begin{enumerate}
    \item By integrating a document ingestion and retrieval module, all thesis documents in PDF format are standardized and divided using thesis-aware boundaries, enriched with metadata, embedded, and indexed in FAISS. This makes them discoverable through semantic search rather than exact keyword matching, resulting in much better retrieval of abstracts, authors, chapters, and themes compared to traditional databases. The pipeline’s token-based chunking and content-type tagging (such as abstract, methodology, or results) really improve context alignment and ranking, so queries like “give me the complete abstract” or “find theses related to nursing” return relevant sections directly, whereas traditional catalogs usually require exact titles or strict keyword fields.

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS as the vector database, using all-MiniLM-L6-v2 from HuggingFace for vector embeddings and Google Gemini 2.5-flash as the generative LLM, user queries are matched to semantically relevant thesis chunks, which consistently yields more precise answers to intent-driven questions (such as complete abstracts, author-focused lookups, or chapter-specific content) than the current yet traditional keyword-based search that depends on exact titles and rigid field matches. The RAG pipeline grounds answers in retrieved chunks, so the chatbot can compose context-aware responses tied to real thesis passages, while the thesis-aware chunking and metadata (abstract, methodology, results, and chapter tags) improve ranking and reduce irrelevant matches.

    \item Using RAGAS as the evaluation framework the system achieved high results in Context Precision (0.9167), Context Recall (0.8711), Answer Relevancy (0.8625), and Faithfulness (0.9179). These values indicate a strong retrieval-and-generation pipeline: high precision and recall show the FAISS-backed retrieval returns the necessary thesis passages, while the strong answer relevancy shows that LLM composes useful responses from retrieved sources. The high faithfulness score suggests that generated outputs are, in most cases, directly grounded in retrieved documents, which materially reduces the likelihood of hallucinations. The evaluation still highlights the usual dependencies and limitations, chiefly the quality and structure of ingested thesis PDFs, OCR/formatting errors, and user prompt variability which remain important targets for continued optimization even as overall performance is strong.
\end{enumerate}

\section{Conclusions}

    Based on the findings, the researchers came up with the following conclusions:

\begin{enumerate}
    \item It was evident that the integration of a thesis-aware document ingestion pipeline was a critical first step in modernizing thesis discovery. By standardizing documents, applying content-aware chunking, and enriching the data with metadata before indexing, the system overcame the limitations of traditional keyword-based catalogs. This approach made thesis content more accessible and discoverable through semantic search, allowing users to find relevant information based on intent rather than exact phrasing.

    \item By implementing a semantic search and thesis retrieval system with RAG orchestrated in LangChain, FAISS for approximate nearest-neighbor search, using all-MiniLM-L6-v2 for vector embeddings and Google Gemini 2.5-flash as the generative LLM, user queries were matched to semantically relevant thesis chunks, which consistently yielded more precise answers to intent-driven questions than the current traditional keyword-based search that depended on exact titles and rigid field matches. By combining semantic search with the generative capabilities of Google Gemini 2.5-flash, the RAG chatbot offered a robust solution for efficient and accurate thesis retrieval in the CSPC Library.

    \item The evaluation demonstrated that the RAG-based chatbot effectively retrieved relevant information and generated contextually appropriate responses. However, it also highlighted the importance of document quality and user input in optimizing performance. Continuous improvements in these areas were essential to enhance the system's reliability and ensure that it consistently met user needs in thesis discovery.
\end{enumerate}

\section{Recommendations}
    \item Future work should focus on enhancing the retrieval-and-generation pipeline by addressing document quality, refining chunking strategies, and optimizing user prompts to further improve context precision, recall, and overall system performance.
    \item Increasing the diversity and volume of ingested thesis documents, and exploring the inclusion of other academic materials (e.g., journal articles, conference papers), can further improve retrieval coverage and system robustness.
    \item To complement automated metrics, future evaluations should include human-in-the-loop assessments, such as expert reviews or user feedback surveys, to better capture subjective aspects of response quality and user satisfaction.
    \item Continued development of the chatbot interface, including user-friendly features like advanced filtering, citation export, and personalized recommendations, will enhance usability and adoption within the academic community.
    \item For broader impact, consider deploying the system on scalable infrastructure and integrating it with other institutional platforms, ensuring accessibility for all CSPC stakeholders.
\end{enumerate}

%=======================================================%
%%%%% Do not delete this part %%%%%%
\clearpage

\printbibliography[heading=subbibintoc, title={\centering Notes}]
\end{refsection}