\chapter{Related Literature and Studies}
\begin{refsection}

This chapter reviews related literature and existing systems on the study. It provides a synthesis of related works, an overview of state-of-the-art technologies and methodologies, and underline the research gaps that the present study has addressed.

\section{Review of Related Literature and Studies}
A review of books, scholarly articles, journals, and previous thesis projects concerning the research topic was carried out to develop an in depth understanding of the subject of the study. The findings are organized thematically in line with the key areas of the study.

\subsection{Large Language Models}

Large Language Models (LLMs) have significantly improved the use case of information retrieval (IR) within academic settings. The integration of LLMs, like ChatGPT and other model architectures, offers notable advancements in natural language processing (NLP) and also proves its capabilities to enhance IR, question-answering, summarization, and content generation, which benefits academic environments where efficient access to information is crucial \cite{yalamanchili2024quality, yang2023large}. Recent works by \citeauthor{khraisha2024can} [\citeyear{khraisha2024can}] and \citeauthor{gartlehner2023data} [\citeyear{gartlehner2023data}] have demonstrated how large language models can automate research tasks such as systematic review, data extraction, and document screening. This suggests that LLMs are capable of improving research productivity in academia \cite{khraisha2024can, gartlehner2023data}.

Even though LLMs offer a number of advantages with regard to information retrieval, they also present significant challenges. Among the major challenges is that they are inefficient at executing domain specific tasks for which specialized knowledge is required. This is because these models source knowledge from pre-training, hence LLMs  are limited to offer fact based responses within certain domains such as academia. Omar et al. mentioned in their study that LLMs, including ChatGPT, could be helpful in specialized domains to serve complementary purposes but may fail in complicated queries because they have not seen enough training data related to those fields \cite{khraisha2024can}. Moreover, pre-trained LLMs have difficulty keeping on pace with continuous data growth in various domains, thus, it is impossible for them to refresh their knowledge without extensive fine-tuning. Lucas et al. point out that this inability-in an academic and professional sense-of large language models to access up-to-date domain-specific repositories significantly diminishes their effectiveness and value \cite{gartlehner2023data}.

Despite of LLMs being at the lead of NLP innovation, their actual application in domain-specific tasks is deeply prevented by certain challenges. These include real-time data availability, dependence on pre-trained knowledge bases, and ethical concerns pertaining to data privacy. Innovation around these challenges using novel methodologies, such as the retrieval-augmented generation approach, increases the capability of models to meet specialized applications that have strict requirements.

\subsection{Retrieval-Augmented Generation}

RAG has achieved remarkable improvements in the IR domain, especially in tasks regarding literature search and thesis retrieval in library systems \cite{thomo2024pubmed}. The architecture supports the traditional large language models with external knowledge sources for enhancing the relevance, richness, and correctness of the responses \cite{chen2024benchmarking}.

As articulated in the studies of \citeauthor{lewis2020retrieval} [\citeyear{lewis2020retrieval}] titled "Retrieval-Augmented Generation for Knowledge Intensive NLP Tasks," RAG provides for much more accurate responses because it helps in addressing certain inherent limitations of LLMs, especially in the areas of accurate knowledge retrieval and context relevance. Another academic study about the topic is the the study of \citeauthor{shuster2021retrieval} [\citeyear{shuster2021retrieval}], titled "Retrieval Augmentation Reduces Hallucination in Conversation," go on to show that RAG reduces inconsistencies and hallucinations in the LLM outputs. Their results show that RAG mechanisms increase conversational fluency and integrity, particularly in open domain conversational settings, bringing about knowledgeable and more coherent responses.

Moreover, it has recently been further supported by work titled "GENAI: RAG Use Cases with Vector DB to Solve the Limitations of LLMs," in which the authors demonstrate that the integration of vector databases with RAG essentially improves retrieval speed and relevance. Semantic search using vector databases makes continuous real-time updates possible for dynamic domains such as business and academic libraries, resulting in a high level of knowledge management and factual correctness in the generated responses. Thus, RAG strengthens not only the capability of LLM retrieval but also addresses the essential weaknesses of LLMs: consistency and factuality \cite{sagi2024genai}.

\subsection{Document Ingestion and Retrieval}

Successful execution of RAG systems relies on utilizing documents in an effective manner and carrying out robust retrieval procedures, particularly in addressing large and complex datasets found in academic libraries. RAG systems can use any data source, including text, video, images, and audio, thus allowing flexible and contextually rich information retrieval. In study this about RAG, the main corpus mostly used is PDF documents to extract academic content which focuses by this authors \cite{li2023extracting}.

The RAG chatbot rely its effectiveness by depending on the quality of preprocessing, which involves converting unstructured PDF data into machine readable formats suitable for embedding and semantic search \cite{arzideh2024miracle, aquino2024extracting}. The PyPDF2, PyMuPDF, and pypdfium are the commonly used tools for this task in most studies to help in extracting raw text from complex PDF layouts \cite{adhikari2024comparative}.

A study by \citeauthor{sagi2024genai} [\citeyear{sagi2024genai}], "GENAI: RAG Use Cases with Vector DB to Solve the Limitations of LLMs," further corroborates this idea by showing how the introduction of vector databases significantly improves retrieval speed and relevance when integrated into RAG. The semantic search capabilities of the vector databases in turn support continuous real-time updates in dynamic domains like academic and business libraries, hence greatly improving knowledge management and factual accuracy of responses generated.Therefore, RAG enhances not only the retrieval capabilities of LLMs but also considerably mitigates its traditional deficiencies in consistency and factual accuracy \cite{sagi2024genai}.

\citeauthor{adhikari2024comparative} [\citeyear{adhikari2024comparative}] into their examined different kind of PDF parsers using F1 score, BLEU-4, and local alignment on a wide range of document types. The results show that PyMuPDF and pypdfium more reliable to retain sentence structure and format than the other tools, something highly recommended for retaining semantic coherence and offering proper vectorization and retrieval. One can also observe parsing difficulties posed by complex documents, such as scientific articles and patent PDFs, for which rule-based tools significantly underperform versus transformer-based models \cite{adhikari2024comparative}.

As stated out by \citeauthor{zhang2023automated} [\citeyear{zhang2023automated}], automated ingestion pipelines parsing documents into a searchable database improve the discoverability and access to scholarly content.

Techniques like OCR, metadata extraction, and structured indexing are common practices employed on thesis repositories to enable various retrieval operations easily \cite{zhang2023automated}. Along related lines, \citeauthor{karpukhin2020dense} [\citeyear{karpukhin2020dense}] stress the importance of document preprocessing, chunking, and embedding to permit semantic search in DPR and, consequently, for modern RAG \cite{karpukhin2020dense}. Generally, this ingestion process consists of several steps: (1) extracting text with PyMuPDF or pypdfium, among other tools; (2) chunking the text into smaller, logically coherent pieces; and (3) embedding by models such as Sentence-BERT. Later, these vectors will be kept in specialized vector databases (e.g., FAISS, Pinecone) so that the actual retrieve action when users make inquiries will be fast and efficient. Hence, robust document ingestion and storage directly impact retrieval accuracy, system responsiveness, and user experience. Taking as its basis on Sagi’s study, it is clear that effectiveness in ingestion and vectorization yields fast retrieval of relevant information and generates very high accuracy, context enriched responses from RAG models, particularly within domain like academic libraries \cite{karpukhin2020dense}. 

The authors in \citeauthor{deepak2025langchain} [\citeyear{deepak2025langchain}], "LangChain-Chat with My PDF", present the prevalent workflow for processing PDFs, which is focused on embedding and chunking within the general techniques of vectorization. This work illustrates how chunking enables RAG to retrieve the most relevant document segments in order to answer user queries and hence better handle long PDF enhancing search capabilities within the system \cite{deepak2025langchain}.

Taken together, these works suggest that perfectly done preprocessing, data ingestion, and vectorization form is crucial for bridging static document repositories with real-time information retrieval, demonstrating the potential for RAG architectures in managing large collections of academic knowledge \cite{allu2024beyond, aquino2024extracting}.

\subsection{RAG Applications in Various Domains}

Beyond contexts in the field of academics, RAG frameworks are increasingly applied to specialized domains, including legal research, medical information retrieval, and scientific literature search, underlining broad versatility and impact.

In the academic domain, \citeauthor{grigoryan2024building} [\citeyear{grigoryan2024building}] proposed a solid foundation for future advancements in academic information retrieval through their study ”Building a Retrieval-Augmented Generation (RAG) System for Academic Papers,” creating a RAG system that  retrieves and analyzes a vast amount of academic papers. They used vector search techniques like cosine similarity and HNSW indexing on the paper’s abstracts and full texts to pass only relevant information to LLM,  which significantly enhanced the retrieval and generation \cite{grigoryan2024building}. This was also supported by \citeauthor{aytar2024retrieval} [\citeyear{aytar2024retrieval}], that proposed enhanced RAG architecture for academic literature navigation in data science, introducing their approached of semantic chunking and an Abstract-First strategy, which significantly enhances the capability of RAG to retrieve pertinent academic content. \cite{aytar2024retrieval}.

% \citeauthor{arzideh2024miracle} [\citeyear{arzideh2024miracle}] underline that in healthcare contexts, RAG is very effective within the scope of domain specific clinical embeddings. Their work, "MIRACLE-Medical Information Retrieval using Clinical Language Embeddings for Retrieval Augmented Generation at the Point of Care," significantly enhances clinical decision making, improves workflows in clinical documentation, and personalizes access to health information. On the basis of the above statement. \citeauthor{amugongo2024retrieval} [\citeyear{amugongo2024retrieval}] note that the RAG architecture is able to retrieve external medical data in a very effective manner, thus providing responses with high levels of accuracy and reliability while minimizing the limitations characteristic of traditional large language models. Similarly, in the legal domain, a study by \citeauthor{aquino2024extracting} [\citeyear{aquino2024extracting}] notes that RAG systems greatly enhance legal research by speeding up the retrieval of cases and statutes and enhancing the authenticity and contextual accuracy of the output.

% Beyond contexts in the field of academics, RAG frameworks are increasingly applied to specialized domains, including legal research, medical information retrieval, and scientific literature search, underlining broad versatility and impact.

In the healthcare domain, As \citeauthor{arzideh2024miracle} [\citeyear{arzideh2024miracle}] point out,  using domain specific clinical embeddings makes the RAG approach highly effective. Their work, "MIRACLE-Medical Information Retrieval using Clinical Language Embeddings for Retrieval Augmented Generation at the Point of Care," have enhances clinical decision making, improves workflows in documentation, and personalizes access to health information. 
Supporting this, \citeauthor{amugongo2024retrieval} [\citeyear{amugongo2024retrieval}] note that the RAG architecture is able to retrieve external medical data in a very effective manner, thus providing responses with high levels of accuracy and reliability while minimizing the limitations characteristic of traditional LLMs. 

Similarly, in the legal domain, a study by \citeauthor{aquino2024extracting} [\citeyear{aquino2024extracting}] notes that RAG systems greatly enhance legal research by speeding up the retrieval of cases and statutes and enhancing the authenticity and contextual accuracy of the output.

In conclusion, these studies collectively show that RAG has already been applied on various domains, from academic research to other specialized fields. Majority of the findings highlights that by using various techniques within the RAG architecture can enhance any domain-specific tasks in a way  that traditional LLM cannot achieve.

\subsection{Evaluation of Retrieval-Augmented Generation (RAG) Systems}

Evaluation of RAG systems requires methodological extensions beyond those applied in traditional designs for large language models. The RAGAS framework presents a structured way of evaluating the context precision, contextual relevance, and faithfulness in a generated response. Studies of \citeauthor{shuster2021retrieval} [\citeyear{shuster2021retrieval}] shows that high quality retrieval has a great effect on user satisfaction and perceived reliability with respect to conversational AI. This, therefore, underlines the need for specialized evaluation frameworks which can guarantee the effectiveness of RAG systems. 

In specialized needs, metrics tailored for RAG models come into pivotal consideration. One of the widely used approaches is the RAGAS evaluation framework that provides key metrics such as Context Recall, Faithfulness, and Response Relevance. These metrics assess the degree to which the retrieved documents substantiate the generated response \cite{roychowdhury2024evaluation}. Context Precision characterizes the share of relevant chunks inside the contexts retrieved, while Context Recall ensures that no important information is missed. Faithfulness checks factual coherence between generated responses and the respective retrieved documents, while Response Relevance checks if the response correctly addresses user query \cite{aquino2024extracting} \cite{deepak2025langchain}.

However, while automated measures may be more valid for some purposes, they often lack coverage of the qualitative dimensions of consistency, fluency, and overall user satisfaction. Human evaluation, according to \citeauthor{sivasothy2024ragprobe} [\citeyear{sivasothy2024ragprobe}], is necessary in improving these systems, since it considers factors that the automated approaches may fail to address.


\section{Synthesis of the State-of-the-Art}

The related literature and systems discussed have substantial relevance to the problem of the study. To have a clear understanding of this literature and studies, the researchers made a synthesis in the succeeding discussions.

LLM with integrated RAG techniques have greatly improved the knowledge-intensive NLP tasks, overcoming LLMs' challenges. The studies of \citeauthor{thapa2022splitfed} [\citeyear{thapa2022splitfed}] and \citeauthor{thomo2024pubmed} [\citeyear{thomo2024pubmed}] on how combining RAG with LLMs significantly improves accuracy and coherence in conversations and complex queries. The advantage of this technique enables LLMs to retrieve relevant external data, reducing hallucinations and improving factual consistency \cite{thapa2022splitfed, thomo2024pubmed}. Furthermore, \citeauthor{lewis2020retrieval} [\citeyear{lewis2020retrieval}] discussed the application of vector databases for continuous integration with RAG, which shows a significant improvement in both retrieval efficiency and the relevance of output produced by large language models . This topic plays a major role in literature searching and retrieving theses from university libraries \cite{lewis2020retrieval}.

A collection of various studies compiled on the use of RAG in different domains is discussed below. For instance, \citeauthor{arzideh2024miracle} [\citeyear{arzideh2024miracle}] incorporated clinical language embeddings into RAG for better healthcare information \cite{arzideh2024miracle}. \citeauthor{grigoryan2024building} [\citeyear{grigoryan2024building}], in "Building a Retrieval-Augmented Generation (RAG) System for Academic Papers," proposes a system that augments academic retrieval through vector search \cite{grigoryan2024building}. Further, \citeauthor{aquino2024extracting} [\citeyear{aquino2024extracting}] used RAG on the effective extraction and analysis of Brazilian legal \cite{aquino2024extracting}. Together, these reports illustrate the adaptability of RAG and its potential to transform how university libraries search for and provide access to academic theses.

Evaluation metrics are important for evaluating the performance of RAG in retrieving and generating accurate responses. Specific metrics of RAGAS, such as Context Precision, Faithfulness, and Answer Relevance, as emphasized in the studies of \citeauthor{sagi2024genai} [\citeyear{sagi2024genai}] and \citeauthor{arzideh2024miracle} [\citeyear{arzideh2024miracle}], ensure the authenticity and consistency of the generated outputs of the model \cite{sagi2024genai,arzideh2024miracle}. Despite the effectiveness of automated metrics, human evaluation remains important to assess coherence and user satisfaction, as mentioned in this study \cite{aquino2024extracting}.

In summary, RAG integrated with LLMs presents a groundbreaking method for improving literature searches and thesis retrieval in university libraries, especially at CSPC library. Through testing the limitations and obstacles faced by traditional LLMs, the integration of RAG reveals its promise to transform research accessibility at the CSPC library.

\section{Gap Bridge of the Study}

% in first gap, the gap of the papers you put in the RRL chapter. Second gap, your reason of ur gap

Existing literatures has explored the applicability of RAG in domains from academic research to other specialized fields, it is concerning to note that there's a gap in the way of specific applications of these systems to academic libraries for enhancing literature searches and thesis retrievals. While previous studies have shown how well RAG improves information retrieval, not much has been done in applying this within university libraries, where there is a unique challenges and requirements that such implementations needed.

This study tries to fill this gap by designing a RAG-based chatbot system specific to the CSPC library. By focusing on the unique challenges and demands of academic libraries, this paper seeks to add substantial value in understanding the appropriate application of RAG systems toward improvement of information retrieval.


%=======================================================%
%%%%% Do not delete this part %%%%%%
\clearpage

\printbibliography[heading=subbibintoc, title={\centering Notes}]
\end{refsection}