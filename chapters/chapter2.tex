\chapter{Related Literature and Studies}
\begin{refsection}

This chapter presents the analysis of relevant literature and existing systems associated with the study. It includes a summary of related works, a synthesis of the state of-the-art technologies and methodologies, and identifies the research gaps addressed by the current study.

\section{Review of Related Literature and Studies}
To develop a deeper understanding of the research topic, a comprehensive review of books, scholarly articles, journals, and previous thesis projects was conducted. The findings are organized thematically to align with the key areas of the study.

\subsection{Large Language Models}

Large Language Models (LLMs) have significantly improved the use case of information retrieval (IR) within academic settings. The integration of LLMs, like ChatGPT and other model architectures, offers notable advancements in natural language processing (NLP) and also proves its capabilities to enhance IR, question-answering, summarization, and content generation, which benefits academic environments where efficient access to information is crucial \cite{yalamanchili2024quality} \cite{yang2023large}. For instance, the recent studies of \citeauthor{khraisha2024can} \citeyear{khraisha2024can} and \citeauthor{gartlehner2023data} \citeyear{gartlehner2023data} reveal that LLMs are capable of automating processes like systematic review, data extraction, and document screening, which demonstrate the capability and potential of LLMs in enhancing the efficiency of academic research \cite{khraisha2024can}  \cite{gartlehner2023data}.

While large language models (LLMs) offer advantages for information retrieval, they also come with challenges. One major challenge is that their inefficient when applied to domain-specific tasks that require specialized knowledge. This limitation occurs because of the models' dependency on their pre-trained knowledge, which limits them from providing factual answers for specific domains, like in Academe. Omar et al. discussed that LLMs, such as ChatGPT, serve as complementary tools in specialized scenarios but may struggle with complex queries due to a lack of exposure to field-specific training data \cite{khraisha2024can}. Additionally, pre-trained LLMs encounter challenges in keeping up with constant expansions of data in various domains, which makes them incapable of updating their knowledge without extensive fine-tuning. Lucas et al. highlighted that for applications in academic and professional settings, the inability of LLMs to access current domain-specific repositories reduces their effectiveness and utility \cite{gartlehner2023data}.

While LLMs stand at the forefront of NLP innovation, substantial limitations arise in their application to domain-specific tasks. These include real-time data retrieval, pre-trained knowledge bases, and ethical considerations surrounding data privacy. Addressing these challenges through innovative approaches like RAG can help leverage the models' capabilities, ensuring they can meet the rigorous demands of specialized applications.

\subsection{Retrieval-Augmented Generation}

Retrieval-Augmented Generation (RAG) has conveyed notable progress in information retrieval (IR), especially in the context of literature search and thesis retrieval in library systems \cite{thomo2024pubmed}. The concept integrates traditional large language models (LLMs) with external knowledge sources to enhance response relevance, richness, and correctness \cite{chen2024benchmarking}.

\citeauthor{lewis2020retrieval} \citeyear{lewis2020retrieval}, in their influential study "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks," emphasized that RAG enables more precise responses by overcoming the inherent limitations of LLMs, particularly regarding accurate knowledge retrieval and contextual relevance. Extending this, \citeauthor{shuster2021retrieval} \citeyear{shuster2021retrieval}, in their study "Retrieval Augmentation Reduces Hallucination in Conversation," showed that RAG reduces inconsistencies and hallucinations in LLM responses. Their findings indicated that RAG mechanisms significantly improved conversational fluency and integrity, especially in open-domain contexts, resulting in more knowledgeable and coherent outputs.

 \citeauthor{sagi2024genai} \citeyear{sagi2024genai}, study "GENAI: RAG Use Cases with Vector DB to Solve the Limitations of LLMs," further reinforced this by demonstrating that combining vector databases with RAG significantly enhances retrieval speed and relevance. Particularly in dynamic domains like academic and business libraries, the semantic search capabilities of vector databases support continuous real-time updates, greatly improving knowledge management and the factuality of generated responses. Thus, RAG not only strengthens the retrieval capabilities of LLMs but also substantially mitigates their traditional weaknesses in consistency and factual accuracy \cite{sagi2024genai}.

\subsection{Document Ingestion and Retrieval}

The performance of Retrieval-Augmented Generation (RAG) systems depends on efficient document use and retrieval procedures, especially when working with large, complicated datasets like academic libraries. Any type of data source, including text, video, images, and audio, can be used with retrieval-augmented generation (RAG) systems, allowing for flexible and contextually rich information retrieval. In this study, the researchers focused on utilizing PDF documents as the primary corpus for academic content extraction \cite{li2023extracting}. 

The effectiveness of RAG systems heavily depends on the quality of preprocessing, which involves converting unstructured PDF data into machine-readable formats suitable for embedding and semantic search \cite{arzideh2024miracle} \cite{aquino2024extracting}. Tools such as PyPDF2, PyMuPDF, and pypdfium are commonly employed for this task, enabling the extraction of raw text from complex PDF layouts \cite{adhikari2024comparative}.

 \citeauthor{sagi2024genai} \citeyear{sagi2024genai}, study "GENAI: RAG Use Cases with Vector DB to Solve the Limitations of LLMs," further reinforced this by demonstrating that combining vector databases with RAG significantly enhances retrieval speed and relevance. Particularly in dynamic domains like academic and business libraries, the semantic search capabilities of vector databases support continuous real-time updates, greatly improving knowledge management and the factuality of generated responses. Thus, RAG not only strengthens the retrieval capabilities of LLMs but also substantially mitigates their traditional weaknesses in consistency and factual accuracy \cite{sagi2024genai}.

\bigbreak
 \citeauthor{adhikari2024comparative} \citeyear{adhikari2024comparative} evaluated several PDF parsers using F1 score, BLEU-4, and local alignment across diverse document categories. Their study revealed that PyMuPDF and pypdfium consistently preserved sentence structure and layout more accurately than other tools. These capabilities are essential for maintaining the necessary semantic coherence for accurate vectorization and retrieval. They also highlighted parsing difficulties in complex documents such as scientific and patent PDFs, where rule-based tools struggled while transformer-based models demonstrated significant improvements. Moreover, efficient document ingestion and retrieval are crucial in managing large repositories such as academic libraries \cite{adhikari2024comparative}.

According to \citeauthor{zhang2023automated} \citeyear{zhang2023automated}, automated ingestion pipelines that parse and store documents in a searchable index improve the discoverability and accessibility of scholarly content. 

Techniques like optical character recognition (OCR), metadata extraction, and structured indexing are often applied to thesis repositories to facilitate retrieval operations \cite{zhang2023automated}. Similarly, \citeauthor{karpukhin2020dense} \citeyear{karpukhin2020dense} emphasized the importance of pre-processing, chunking, and embedding documents for semantic search in their work on Dense Passage Retrieval (DPR), informing modern RAG pipelines \cite{karpukhin2020dense}. Typically, the ingestion process involves multiple steps: (1) text extraction using tools like PyMuPDF or pypdfium, (2) text chunking into smaller, logical parts, and (3) embedding using models like Sentence-BERT. Finally, these vectors are stored in specialized vector databases such as FAISS, Pinecone, or FAISS for efficient retrieval during user queries. Efficient document ingestion and storage directly influence retrieval accuracy, system responsiveness, and user experience. Sagi emphasized that robust ingestion and vectorization processes ensure that relevant information can be retrieved quickly and that RAG models generate highly accurate, contextually rich responses, especially in dynamic environments like academic libraries \cite{karpukhin2020dense}.

\citeauthor{deepak2025langchain} \citeyear{deepak2025langchain}, in their study "Langchain-chat with my pdf" highlighted the significance of vectorization techniques such as embedding and chunking in processing PDFs. Their research illustrated how chunking aids the RAG framework in identifying relevant sections of documents during user queries, streamlining the management of comprehensive PDF-based information, and enhancing the system's semantic search capabilities \cite{deepak2025langchain}.

\bigbreak
In conclusion, the studies collectively highlight that robust preprocessing, ingestion, and vectorization processes are foundational for bridging the gap between static document repositories and real-time information retrieval, demonstrating the potential of RAG architectures in managing large collections of academic knowledge \cite{allu2024beyond} \cite{aquino2024extracting}.

\subsection{RAG Applications in Various Domains}

Beyond academic contexts, RAG frameworks are increasingly being applied to specialized domains such as legal research, medical retrieval, and scientific literature search, highlighting their wide versatility and impact.

In the academic domain, \citeauthor{grigoryan2024building} \citeyear{grigoryan2024building}, in their study "Building a Retrieval-Augmented Generation (RAG) System for Academic Papers," developed a RAG-powered system that significantly enhanced academic literature retrieval using vector search techniques like cosine similarity and HNSW indexing \cite{grigoryan2024building}. Similarly, \citeauthor{song2024travelrag} \citeyear{song2024travelrag} emphasized that RAG frameworks not only improve search capability but also boost academic outputs by integrating external knowledge into LLMs, leading to more accurate and efficient information retrieval for students and researchers \cite{song2024travelrag}. Their findings align with those of \citeauthor{karpukhin2020dense} \citeyear{karpukhin2020dense}, who also reported that better information retrieval accuracy correlates with improved search results and question-answering performance \cite{karpukhin2020dense}.


In the healthcare domain, \citeauthor{arzideh2024miracle} \citeyear{arzideh2024miracle}, in "MIRACLE - Medical Information Retrieval using Clinical Language Embeddings for Retrieval Augmented Generation at the Point of Care," demonstrated the effectiveness of RAG systems integrated with domain-specific clinical embeddings \cite{arzideh2024miracle}. Their approach greatly improved clinical decision-making, supported efficient documentation workflows, and offered greater personalization in healthcare information access. Supporting this, \citeauthor{amugongo2024retrieval} \citeyear{amugongo2024retrieval} showed that RAG systems could successfully retrieve external medical data to generate highly accurate, reliable responses, surpassing traditional LLM limitations \cite{amugongo2024retrieval}.

In the legal field, \citeauthor{aquino2024extracting} \citeyear{aquino2024extracting}, in their study "Extracting Information from Brazilian Legal Documents with Retrieval Augmented Generation," illustrated that RAG systems significantly optimize legal research by speeding up case law retrieval and improving the authenticity and contextual accuracy of outputs \cite{aquino2024extracting}. 

% Similarly, \citeauthor{ryu2023retrieval} \citeyear{ryu2023retrieval}, in "Retrieval-Augmented Generation for Legal Question-Answering," validated RAG's effectiveness in legal question-answering tasks, demonstrating that RAG-enhanced models outperformed standard LLMs in accuracy and relevance when addressing complex legal queries \cite{ryu2023retrieval}.

Finally, recent advancements such as Google Gemini, a state-of-the-art LLM, demonstrate that when integrated with RAG mechanisms \citeauthor{prabhulal2025ragpipeline} \citeyear{prabhulal2025ragpipeline}, LLMs can attain improved semantic understanding and retrieval precision \cite{prabhulal2025ragpipeline}. In parallel, vector search offers a robust foundation for developing intelligent, document-aware systems. By combining high-quality semantic embeddings with indexing, this approach ensures that responses remain accurate, transparent, and firmly anchored in domain-specific data rather than relying solely on general model knowledge.


\subsection{Evaluation of Retrieval-Augmented Generation (RAG) Systems}

The evaluation of Retrieval-Augmented Generation (RAG) systems requires more specialized approaches than traditional large language model (LLM) benchmarks. RAGAS (Retrieval-Augmented Generation Assessment Scores) provides a structured methodology for assessing retrieval precision, context relevance, and the faithfulness of generated responses (RAGAS Documentation). Studies such as those by \citeauthor{shuster2021retrieval} \citeyear{shuster2021retrieval} have demonstrated that retrieval quality significantly impacts user satisfaction and perceived reliability of conversational AI, particularly in academic settings. Thus, specialized evaluation frameworks are crucial for ensuring the effectiveness of RAG systems \cite{shuster2021retrieval}.
Building upon the need for specialized evaluation, metrics specifically designed for RAG models play a pivotal role. The RAGAS evaluation framework is widely utilized, emphasizing primary metrics such as Context Recall, Faithfulness, and Response Relevance to measure how well the retrieved documents support the generated response \cite{roychowdhury2024evaluation}.
Context Precision measures the proportion of relevant chunks in the retrieved contexts, while Context Recall ensures that essential information is not omitted. Faithfulness evaluates the factual consistency between generated responses and the retrieved documents, and Response Relevance assesses whether the response addresses the user's query \cite{aquino2024extracting} \cite{deepak2025langchain}.

However, though automated measures are reliable, they frequently fail to assess qualitative aspects like consistency, fluency, and general user happiness.
 
\citeauthor{sivasothy2024ragprobe} \citeyear{sivasothy2024ragprobe} noted that human assessment is still necessary to improve these systems and take into account factors that automated approaches can ignore \cite{sivasothy2024ragprobe}.


\section{Synthesis of the State-of-the-Art}

The related literature and systems discussed have substantial relevance to the problem of the study. To have a clear understanding of this literature and studies, the researchers made a synthesis in the succeeding discussions.


Large Language Models (LLMs) with integrated RAG techniques have greatly improved the knowledge-intensive NLP tasks, overcoming LLMs' challenges. Studies \cite{thapa2022splitfed} and \cite{thomo2024pubmed} underline how combining RAG with LLMs significantly improves accuracy and coherence in conversations and complex queries. The advantage of this technique enables LLMs to retrieve relevant external data, reducing hallucinations and improving factual consistency. Furthermore, the study \cite{lewis2020retrieval} highlighted the use of vector databases for continuous information adaptation integrated with RAG, greatly enhancing retrieval efficiency and relevancy of LLM outputs, which is essential for literature search and thesis retrieval in university libraries.


The application of RAG in various domains is addressed in numerous studies. For instance, the study by \citeauthor{arzideh2024miracle} \citeyear{arzideh2024miracle} incorporates clinical language embeddings within RAG to improve healthcare information retrieval, while the study by \citeauthor{grigoryan2024building} \citeyear{grigoryan2024building}, "Building a Retrieval-Augmented Generation (RAG) System for Academic Papers," presents a system that enhances academic retrieval using vector search. Additionally, \citeauthor{aquino2024extracting} \citeyear{aquino2024extracting} employs RAG for effectively extracting and analyzing Brazilian legal documents, and \citeauthor{ryu2023retrieval} \citeyear{ryu2023retrieval} validates RAGâ€™s effectiveness in legal question-answering tasks. Moreover, Google Gemini, when integrated with a RAG mechanism and supported by vector search, can achieve enhanced semantic understanding, retrieval precision, and responses that are accurate, explainable, and grounded in domain-specific data.


The findings from these various studies demonstrate RAG's flexibility, highlighting its potential to transform how university libraries handle searches and improve access to academic papers.

Evaluation metrics are important for evaluating the performance of RAG in retrieving and generating accurate responses. Specific metrics of RAGAS, such as Context Precision, Faithfulness, and Answer Relevance, as emphasized in the studies \cite{sagi2024genai} and \cite{arzideh2024miracle}, ensure the authenticity and consistency of the generated outputs of the model. Despite the effectiveness of automated metrics, human evaluation remains important in assessing coherence and user satisfaction, as mentioned in this study \cite{aquino2024extracting}.

 In summary, Retrieval-Augmented Generation (RAG) integrated in Large Language Models (LLMs) presents a groundbreaking method for improving literature searches and thesis retrieval in university libraries, especially at CSPC library. By examining the limitations and obstacles faced by traditional LLMs, the integration of RAG reveals its promise to transform research accessibility at the CSPC library.

\section{Gap Bridge of the Study}

% in first gap, the gap of the papers you put in the RRL chapter. Second gap, your reason of ur gap

Existing studies have extensively explored the capabilities of Retrieval-Augmented Generation (RAG) systems in various domains, including healthcare, legal research, and academic literature retrieval. However, there is a notable gap in the literature regarding the specific application of RAG systems within academic libraries, particularly in enhancing literature search and thesis retrieval processes. While previous research has demonstrated the effectiveness of RAG in improving information retrieval, there is limited implementation in the context of university libraries, where unique challenges and requirements exist.

This study aims to bridge this gap by developing a RAG-based chatbot system specifically designed for the CSPC library. By focusing on the unique challenges and requirements of academic libraries, this research seeks to contribute valuable insights into the effective implementation of RAG systems in enhancing information retrieval.


%=======================================================%
%%%%% Do not delete this part %%%%%%
\clearpage

\printbibliography[heading=subbibintoc, title={\centering Notes}]
\end{refsection}
